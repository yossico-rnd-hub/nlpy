{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from math import log\n",
    "\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, decaying, compounding\n",
    "import spacy.about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    with path.open('r') as file_:\n",
    "        for row in csv.DictReader(file_, delimiter=','):\n",
    "            text = row['title']\n",
    "            #text = row['text']\n",
    "            text_labels = row['labels'] # there may be multiple labels per row\n",
    "            for label in text_labels.split(','):\n",
    "                texts.append(text)\n",
    "                labels.append(label.strip())\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def format_data_for_spacy(texts, labels, all_labels):\n",
    "    ys = []\n",
    "    for true_label in labels:\n",
    "        cats = {wrong_label: 0.0 for wrong_label in all_labels}\n",
    "        cats[true_label] = 1.\n",
    "        ys.append({'cats': cats})\n",
    "    return list(zip(texts, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "regex = re.compile(r\"n[ar]\\d+[a-z]*\") # e.g: na18020,nr18030ml\n",
    "\n",
    "def normalize_word(t):\n",
    "    if (t.ent_type_ in ('DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL')):\n",
    "        return t.ent_type_\n",
    "    if t.like_num:\n",
    "        return 'LIKE_NUM'\n",
    "    if t.like_email:\n",
    "        return 'LIKE_EMAIL'\n",
    "    if t.like_url:\n",
    "        return 'LIKE_URL'\n",
    "    if t.is_punct:\n",
    "        return None\n",
    "#     if t.is_stop:\n",
    "#         return None\n",
    "#     if len(t.lemma_) < 3:\n",
    "#         return None\n",
    "    if regex.match(t.lemma_):\n",
    "        return None\n",
    "        \n",
    "    return t.lemma_\n",
    "\n",
    "def clean_text(nlp, text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # merge entities\n",
    "#     for span in doc.ents:\n",
    "#         span.merge()\n",
    "    \n",
    "    # normalize & filter tokens\n",
    "    words = []\n",
    "    for t in doc:\n",
    "        w = normalize_word(t)\n",
    "        if (None != w):\n",
    "            words.append(w)\n",
    "    \n",
    "    # remove duplicated consecutive terms (e.g: DATE DATE... -> DATE)\n",
    "    words = [x[0] for x in groupby(words)]\n",
    "    \n",
    "    # to string\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MURDER\n",
      "City Wide Annual Homicide Report - 2017    NA18022rh\n",
      "city wide annual homicide report LIKE_NUM    \n",
      "\n",
      "NONE\n",
      "Operations-Valley Bureau Human Trafficking Task Force Enforcement Update    NA18020dm\n",
      "operations valley bureau human traffic task force enforcement update     dm\n",
      "\n",
      "THEFT\n",
      "Grand Theft by Trickery      NR18030ml  \n",
      "grand theft by trickery        \n",
      "\n",
      "MURDER\n",
      "Attempt Murder on a Police Officer Suspect arrested in Southwest Division NR18026bm\n",
      "attempt murder on a police officer suspect arrest in southwest division\n",
      "\n",
      "NONE\n",
      "LAPD & “Go Be” Welcome Home Kit Donation NA18016dm\n",
      "lapd go be welcome home kit donation dm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main(data_dir = '../../../data/lapd.labeled'):\n",
    "    data_dir = Path(data_dir)\n",
    "    texts, labels = read_data(data_dir / 'lapd_news_2018.csv')\n",
    "    nlp = spacy.load('en')\n",
    "    clean_texts = [clean_text(nlp, text) for text in texts]\n",
    "    for i in range(5):\n",
    "        print(labels[i])\n",
    "        print(texts[i])\n",
    "        print(clean_texts[i])\n",
    "        print()\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
