{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from math import log\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, decaying, compounding\n",
    "\n",
    "use_titles = False\n",
    "do_clean_text = False\n",
    "model = 'en_core_web_sm'\n",
    "#model = 'en_core_web_lg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    texts = []\n",
    "    true_labels = []\n",
    "    with path.open('r') as file_:\n",
    "        for row in csv.DictReader(file_, delimiter=','):\n",
    "            text = row['title'] if use_titles else row['text']\n",
    "            labels = row['labels'] # could be multiple labels per row\n",
    "            for label in labels.split(';'):\n",
    "                texts.append(text)\n",
    "                true_labels.append(label.strip())\n",
    "    return texts, true_labels\n",
    "\n",
    "\n",
    "def format_data_for_spacy(texts, labels, all_labels):\n",
    "    ys = []\n",
    "    for true_label in labels:\n",
    "        cats = {wrong_label: 0.0 for wrong_label in all_labels}\n",
    "        cats[true_label] = 1.0\n",
    "        ys.append({'cats': cats})\n",
    "    return list(zip(texts, ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "regex = re.compile(r\"n[ar]\\d+[a-z]*\") # e.g: na18020,nr18030ml\n",
    "\n",
    "def clean_text(nlp, text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # merge entities\n",
    "    #for span in doc.ents:\n",
    "    #    span.merge()\n",
    "    \n",
    "    # normalize & filter tokens\n",
    "    words = []\n",
    "    for t in doc:\n",
    "        w = normalize_word(t)\n",
    "        if (None != w):\n",
    "            words.append(w)\n",
    "    \n",
    "    # remove duplicated consecutive terms (e.g: DATE DATE... -> DATE)\n",
    "    words = [x[0] for x in groupby(words)]\n",
    "    \n",
    "    # to string\n",
    "    return ' '.join(words)\n",
    "\n",
    "def normalize_word(t):\n",
    "    if (t.ent_type_ in ('DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL')):\n",
    "        return t.ent_type_\n",
    "    if t.like_num:\n",
    "        return 'LIKE_NUM'\n",
    "    if t.like_email:\n",
    "        return 'LIKE_EMAIL'\n",
    "    if t.like_url:\n",
    "        return 'LIKE_URL'\n",
    "    if t.is_punct:\n",
    "        return None\n",
    "    if t.is_stop:\n",
    "        return None\n",
    "    if len(t.lemma_) < 3:\n",
    "        return None\n",
    "    if regex.match(t.lemma_):\n",
    "        return None\n",
    "        \n",
    "    return t.lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nlp, texts, labels, split=0.8, n_iter=10):\n",
    "    \n",
    "    # add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'textcat' not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe('textcat')\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        textcat = nlp.get_pipe('textcat')\n",
    "\n",
    "    # add labels\n",
    "    label_set = set(labels)\n",
    "    for label in label_set:\n",
    "        textcat.add_label(label)\n",
    "    \n",
    "    # split train/eval\n",
    "    data = format_data_for_spacy(texts, labels, label_set)\n",
    "    random.shuffle(data)\n",
    "    split = int(len(data) * split)\n",
    "    train_data = data[:split]\n",
    "    eval_data = data[split:]\n",
    "    dev_texts = []\n",
    "    dev_cats = []\n",
    "    for index, (t, c) in enumerate(eval_data):\n",
    "        dev_texts.append(t)\n",
    "        dev_cats.append(c)\n",
    "\n",
    "    print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "          .format(len(texts), len(train_data), len(eval_data)))\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "        optimizer = nlp.begin_training()\n",
    "        print(\"Training the model...\")\n",
    "        print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "\n",
    "            print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n",
    "                  .format(losses['textcat'], scores['textcat_p'],\n",
    "                          scores['textcat_r'], scores['textcat_f']))\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]['cats']\n",
    "#         print(' ------------- lilo gold:', gold)\n",
    "        for label, score in doc.cats.items():\n",
    "#             print(' ------------- lilox-1 label:', label)\n",
    "            if label not in gold:\n",
    "                continue\n",
    "#             print(' ------------- lilox-2 score:', score)\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def augment_data(train_data):\n",
    "    return train_data\n",
    "\n",
    "def train2(nlp, texts, labels, models_dir=None, use_default_model=True):\n",
    "    textcat = nlp.create_pipe('textcat')\n",
    "    nlp.add_pipe(textcat)\n",
    "    label_set = set(labels)\n",
    "    for label in label_set:\n",
    "        textcat.add_label(label)\n",
    "    train_data = format_data_for_spacy(texts, labels, label_set)\n",
    "    random.shuffle(train_data)\n",
    "    eval_data = train_data[:1000]\n",
    "    train_data = train_data[len(eval_data):]\n",
    "    optimizer = nlp.begin_training()\n",
    "    if not use_default_model:\n",
    "        textcat.model = build_text_classifier(3, width=64, pretrained_dims=300)\n",
    "    best = None\n",
    "#     for i in range(6):\n",
    "    for i in range(10):\n",
    "        losses = {}\n",
    "        augmented = augment_data(train_data)\n",
    "        for j, batch in enumerate(minibatch(augmented, size=128)):\n",
    "            texts, annot = zip(*batch)\n",
    "            nlp.update(texts, annot, sgd=optimizer, losses=losses, drop=0.3)\n",
    "            if j % 10 == 0: # Pretty basic progress reporting\n",
    "                if j:\n",
    "                    print(j, len(batch), 'loss=', losses['textcat'])\n",
    "                losses = {}\n",
    "        with nlp.use_params(optimizer.averages):\n",
    "            acc, loss = evaluate2(nlp, eval_data)\n",
    "            if not best or loss < best[0]:\n",
    "                best = (loss, acc, nlp.to_bytes())\n",
    "                print('Dev acc', loss, acc, '(new best)')\n",
    "            else:\n",
    "                print('Dev acc', loss, acc, '(best: %.2f)' % best[0])\n",
    "    nlp.from_bytes(best[-1]) # Load our best weights back in\n",
    "    return nlp\n",
    "\n",
    "def evaluate2(nlp, eval_data):\n",
    "    right = 0.\n",
    "    wrong = 0.\n",
    "    loss = 0.\n",
    "    for doc, gold in nlp.pipe(eval_data, as_tuples=True):\n",
    "        score, guess = max((score, label) for label, score in doc.cats.items())\n",
    "        if gold['cats'].get(guess):\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "        truth = [a for a, true in gold['cats'].items() if true][0]\n",
    "        loss += log(doc.cats[truth])\n",
    "    loss /= (right + wrong)\n",
    "    print(right, wrong)\n",
    "    return right / (right + wrong), -loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model 'en_core_web_sm'...\n",
      "model loaded.\n",
      "\n",
      "loading data from '../../../data/lapd.labeled'...\n",
      "\n",
      "Using 2576 examples (2060 training, 516 evaluation)\n",
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "284.916\t0.830\t0.560\t0.669\n",
      "192.693\t0.815\t0.614\t0.701\n",
      "160.321\t0.832\t0.612\t0.705\n",
      "138.356\t0.822\t0.626\t0.711\n",
      "117.431\t0.818\t0.651\t0.725\n",
      "103.731\t0.796\t0.649\t0.715\n",
      "95.596\t0.793\t0.647\t0.713\n",
      "89.203\t0.790\t0.649\t0.713\n",
      "90.005\t0.785\t0.630\t0.699\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d52a575e5758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-d52a575e5758>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-2743177a9951>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nlp, texts, labels, split, n_iter)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtextcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# evaluate on the dev data split off in load_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0mdoc_objs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mgold_objs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(data_dir = '../../../data/lapd.labeled'):\n",
    "    \n",
    "    print(\"loading model '{}'...\".format(model))\n",
    "    nlp = spacy.load(model)\n",
    "    print('model loaded.')\n",
    "\n",
    "    print()\n",
    "    print(\"loading data from '{}'...\".format(data_dir))\n",
    "    data_dir = Path(data_dir)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for year in ['2018', '2016', '2015', '2014', '2013']:\n",
    "        t, l = load_data(data_dir / 'lapd_news_{}.csv'.format(year))\n",
    "        texts = texts + t\n",
    "        labels = labels + l\n",
    "    \n",
    "    if do_clean_text:\n",
    "        print()\n",
    "        print('cleaning texts...')\n",
    "        with nlp.disable_pipes('parser'):\n",
    "            clean_texts = [clean_text(nlp, text) for text in texts]\n",
    "            print('clean texts completed.')\n",
    "    else:\n",
    "        clean_texts = texts\n",
    "        \n",
    "#     print()\n",
    "#     for i in range(5):\n",
    "#         print('label:\\t', labels[i])\n",
    "#         print('text:\\t', texts[i])\n",
    "#         if do_clean_text:\n",
    "#             print('clean:\\t', clean_texts[i])\n",
    "#         print()\n",
    "\n",
    "    print()\n",
    "    train(nlp, clean_texts, labels)\n",
    "\n",
    "    print()\n",
    "    print('Done.')\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
