{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from math import log\n",
    "\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, decaying, compounding\n",
    "import spacy.about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    with path.open('r') as file_:\n",
    "        for row in csv.DictReader(file_, delimiter=','):\n",
    "#             text = row['title']\n",
    "            text = row['text']\n",
    "            text_labels = row['labels'] # there may be multiple labels per row\n",
    "            for label in text_labels.split(';'):\n",
    "                texts.append(text)\n",
    "                labels.append(label.strip())\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def format_data_for_spacy(texts, labels, all_labels):\n",
    "    ys = []\n",
    "    for true_label in labels:\n",
    "        cats = {wrong_label: 0.0 for wrong_label in all_labels}\n",
    "        cats[true_label] = 1.\n",
    "        ys.append({'cats': cats})\n",
    "    return list(zip(texts, ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import groupby\n",
    "regex = re.compile(r\"n[ar]\\d+[a-z]*\") # e.g: na18020,nr18030ml\n",
    "\n",
    "def normalize_word(t):\n",
    "    if (t.ent_type_ in ('DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL')):\n",
    "        return t.ent_type_\n",
    "    if t.like_num:\n",
    "        return 'LIKE_NUM'\n",
    "    if t.like_email:\n",
    "        return 'LIKE_EMAIL'\n",
    "    if t.like_url:\n",
    "        return 'LIKE_URL'\n",
    "    if t.is_punct:\n",
    "        return None\n",
    "#     if t.is_stop:\n",
    "#         return None\n",
    "#     if len(t.lemma_) < 3:\n",
    "#         return None\n",
    "    if regex.match(t.lemma_):\n",
    "        return None\n",
    "        \n",
    "    return t.lemma_\n",
    "\n",
    "def clean_text(nlp, text):\n",
    "    return text\n",
    "\n",
    "def clean_text2(nlp, text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # merge entities\n",
    "#     for span in doc.ents:\n",
    "#         span.merge()\n",
    "    \n",
    "    # normalize & filter tokens\n",
    "    words = []\n",
    "    for t in doc:\n",
    "        w = normalize_word(t)\n",
    "        if (None != w):\n",
    "            words.append(w)\n",
    "    \n",
    "    # remove duplicated consecutive terms (e.g: DATE DATE... -> DATE)\n",
    "    words = [x[0] for x in groupby(words)]\n",
    "    \n",
    "    # to string\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(nlp, eval_data):\n",
    "    right = 0.\n",
    "    wrong = 0.\n",
    "    loss = 0.\n",
    "    for doc, gold in nlp.pipe(eval_data, as_tuples=True):\n",
    "        score, guess = max((score, label) for label, score in doc.cats.items())\n",
    "        if gold['cats'].get(guess):\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "        truth = [a for a, true in gold['cats'].items() if true][0]\n",
    "        loss += log(doc.cats[truth])\n",
    "    loss /= (right + wrong)\n",
    "    print(right, wrong)\n",
    "    return right / (right + wrong), -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(train_data):\n",
    "    return train_data\n",
    "\n",
    "def train(nlp, texts, labels, models_dir=None, use_default_model=True):\n",
    "    textcat = nlp.create_pipe('textcat')\n",
    "    nlp.add_pipe(textcat)\n",
    "    label_set = set(labels)\n",
    "    for label in label_set:\n",
    "        textcat.add_label(label)\n",
    "    train_data = format_data_for_spacy(texts, labels, label_set)\n",
    "    random.shuffle(train_data)\n",
    "    eval_data = train_data[:1000]\n",
    "    train_data = train_data[len(eval_data):]\n",
    "    optimizer = nlp.begin_training()\n",
    "    if not use_default_model:\n",
    "        textcat.model = build_text_classifier(3, width=64, pretrained_dims=300)\n",
    "    best = None\n",
    "#     for i in range(6):\n",
    "    for i in range(10):\n",
    "        losses = {}\n",
    "        augmented = augment_data(train_data)\n",
    "        for j, batch in enumerate(minibatch(augmented, size=128)):\n",
    "            texts, annot = zip(*batch)\n",
    "            nlp.update(texts, annot, sgd=optimizer, losses=losses, drop=0.3)\n",
    "            if j % 10 == 0: # Pretty basic progress reporting\n",
    "                if j:\n",
    "                    print(j, len(batch), 'loss=', losses['textcat'])\n",
    "                losses = {}\n",
    "        with nlp.use_params(optimizer.averages):\n",
    "            acc, loss = evaluate_model(nlp, eval_data)\n",
    "            if not best or loss < best[0]:\n",
    "                best = (loss, acc, nlp.to_bytes())\n",
    "                print('Dev acc', loss, acc, '(new best)')\n",
    "            else:\n",
    "                print('Dev acc', loss, acc, '(best: %.2f)' % best[0])\n",
    "    nlp.from_bytes(best[-1]) # Load our best weights back in\n",
    "    return nlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "model loaded\n",
      "loading data...\n",
      "2013 loaded\n",
      "2014 loaded\n",
      "2015 loaded\n",
      "2016 loaded\n",
      "2018 loaded\n",
      "cleaning texts...\n",
      "clean texts completed.\n",
      "training...\n",
      "10 128 loss= 47.774677872657776\n",
      "601.0 399.0\n",
      "Dev acc 1.9557904177067544 0.601 (new best)\n",
      "10 128 loss= 9.507182240486145\n",
      "677.0 323.0\n",
      "Dev acc 3.0052171594813877 0.677 (best: 1.96)\n",
      "10 128 loss= 6.775708854198456\n",
      "682.0 318.0\n",
      "Dev acc 3.07886943837287 0.682 (best: 1.96)\n",
      "10 128 loss= 6.3964791893959045\n",
      "682.0 318.0\n",
      "Dev acc 3.1245087199826322 0.682 (best: 1.96)\n",
      "10 128 loss= 6.2348712682724\n",
      "682.0 318.0\n",
      "Dev acc 3.144447682657951 0.682 (best: 1.96)\n",
      "10 128 loss= 6.228236734867096\n",
      "682.0 318.0\n",
      "Dev acc 3.154139798565255 0.682 (best: 1.96)\n",
      "10 128 loss= 6.223338603973389\n",
      "682.0 318.0\n",
      "Dev acc 3.1592184604430598 0.682 (best: 1.96)\n",
      "10 128 loss= 6.058074951171875\n",
      "682.0 318.0\n",
      "Dev acc 3.1660231819033386 0.682 (best: 1.96)\n",
      "10 128 loss= 5.163029968738556\n",
      "682.0 318.0\n",
      "Dev acc 3.18053343654992 0.682 (best: 1.96)\n",
      "10 128 loss= 4.514303386211395\n",
      "682.0 318.0\n",
      "Dev acc 3.271881888631698 0.682 (best: 1.96)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E008] Some current components would be lost when restoring previous pipeline state. If you added components after calling `nlp.disable_pipes()`, you should remove them explicitly with `nlp.remove_pipe()` before the pipeline is restored. Names of the new components: ['textcat']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-74905c4913ca>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_pipes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_pipes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only train textcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-84dbe16af45b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nlp, texts, labels, models_dir, use_default_model)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dev acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(best: %.2f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load our best weights back in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(self, bytes_data, disable)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mdeserializers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(bytes_data, setters, exclude)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    680\u001b[0m             ('vocab', lambda b: (\n\u001b[0;32m--> 681\u001b[0;31m                 self.vocab.from_bytes(b) and _fix_pretrained_vectors_name(self))),\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_bytes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(bytes_data, setters, exclude)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_bytes.lambda4\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_bytes.serialize_vectors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.from_bytes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(bytes_data, setters, exclude)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mvectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.from_bytes.deserialize_weights\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/msgpack_numpy.py\u001b[0m in \u001b[0;36munpackb\u001b[0;34m(packed, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object_hook'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_unpackb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmsgpack/_unpacker.pyx\u001b[0m in \u001b[0;36mmsgpack._unpacker.unpackb\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-74905c4913ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-74905c4913ca>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mother_pipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpipe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'textcat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_pipes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_pipes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only train textcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py/nlpy/env/lib/python3.5/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;31m# Don't change the pipeline if we're raising an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE008\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E008] Some current components would be lost when restoring previous pipeline state. If you added components after calling `nlp.disable_pipes()`, you should remove them explicitly with `nlp.remove_pipe()` before the pipeline is restored. Names of the new components: ['textcat']"
     ]
    }
   ],
   "source": [
    "def main(data_dir = '../../../data/lapd.labeled'):\n",
    "    \n",
    "    print('loading model...')\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    print('model loaded')\n",
    "\n",
    "    print('loading data...')\n",
    "    data_dir = Path(data_dir)\n",
    "    texts_2013, labels_2013 = read_data(data_dir / 'lapd_news_2013.csv')\n",
    "    print('2013 loaded')\n",
    "    texts_2014, labels_2014 = read_data(data_dir / 'lapd_news_2014.csv')\n",
    "    print('2014 loaded')\n",
    "    texts_2015, labels_2015= read_data(data_dir / 'lapd_news_2015.csv')\n",
    "    print('2015 loaded')\n",
    "    texts_2016, labels_2016 = read_data(data_dir / 'lapd_news_2016.csv')\n",
    "    print('2016 loaded')\n",
    "    texts_2018, labels_2018 = read_data(data_dir / 'lapd_news_2018.csv')\n",
    "    print('2018 loaded')\n",
    "    texts = texts_2013 + texts_2014 + texts_2015 + texts_2016 + texts_2018\n",
    "    labels = labels_2013 + labels_2014 + labels_2015 + labels_2016 + labels_2018\n",
    "    print('cleaning texts...')\n",
    "    clean_texts = [clean_text(nlp, text) for text in texts]\n",
    "    print('clean texts completed.')\n",
    "#     for i in range(5):\n",
    "#         print(labels[i])\n",
    "#         print(texts[i])\n",
    "#         print(clean_texts[i])\n",
    "#         print()\n",
    "    print('training...')\n",
    "    best = train(nlp, clean_texts, labels)\n",
    "    \n",
    "    print('Done.')\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
